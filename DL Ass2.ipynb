{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT - 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "Convolutional neural network (CNN) (Any One from the following)\n",
    "- Use any dataset of plant disease and design a plant disease detection system using CNN.\n",
    "- Use MNIST Fashion Dataset and create a classifier to classify fashion clothing into\n",
    "categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 14us/step\n",
      "40960/29515 [=========================================] - 0s 11us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 342s 13us/step\n",
      "26435584/26421880 [==============================] - 342s 13us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 102s 23us/step\n",
      "4431872/4422102 [==============================] - 102s 23us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "testX = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "trainX = trainX/255\n",
    "testX = testX/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de7d362f70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = np_utils.to_categorical(y_train,10)\n",
    "testY = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1), input_shape=(28,28,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 19s - loss: 0.5701 - accuracy: 0.7950 - val_loss: 0.3959 - val_accuracy: 0.8588\n",
      "Epoch 2/20\n",
      "469/469 - 19s - loss: 0.3656 - accuracy: 0.8667 - val_loss: 0.3594 - val_accuracy: 0.8684\n",
      "Epoch 3/20\n",
      "469/469 - 20s - loss: 0.3156 - accuracy: 0.8848 - val_loss: 0.3060 - val_accuracy: 0.8875\n",
      "Epoch 4/20\n",
      "469/469 - 20s - loss: 0.2887 - accuracy: 0.8947 - val_loss: 0.2987 - val_accuracy: 0.8904\n",
      "Epoch 5/20\n",
      "469/469 - 20s - loss: 0.2641 - accuracy: 0.9040 - val_loss: 0.2926 - val_accuracy: 0.8923\n",
      "Epoch 6/20\n",
      "469/469 - 20s - loss: 0.2457 - accuracy: 0.9093 - val_loss: 0.2582 - val_accuracy: 0.9042\n",
      "Epoch 7/20\n",
      "469/469 - 20s - loss: 0.2293 - accuracy: 0.9148 - val_loss: 0.2529 - val_accuracy: 0.9085\n",
      "Epoch 8/20\n",
      "469/469 - 21s - loss: 0.2140 - accuracy: 0.9210 - val_loss: 0.2512 - val_accuracy: 0.9066\n",
      "Epoch 9/20\n",
      "469/469 - 21s - loss: 0.2012 - accuracy: 0.9254 - val_loss: 0.2589 - val_accuracy: 0.9073\n",
      "Epoch 10/20\n",
      "469/469 - 21s - loss: 0.1856 - accuracy: 0.9308 - val_loss: 0.2392 - val_accuracy: 0.9145\n",
      "Epoch 11/20\n",
      "469/469 - 22s - loss: 0.1742 - accuracy: 0.9353 - val_loss: 0.2575 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "469/469 - 22s - loss: 0.1645 - accuracy: 0.9384 - val_loss: 0.2446 - val_accuracy: 0.9122\n",
      "Epoch 13/20\n",
      "469/469 - 22s - loss: 0.1547 - accuracy: 0.9417 - val_loss: 0.2603 - val_accuracy: 0.9138\n",
      "Epoch 14/20\n",
      "469/469 - 22s - loss: 0.1439 - accuracy: 0.9452 - val_loss: 0.2460 - val_accuracy: 0.9147\n",
      "Epoch 15/20\n",
      "469/469 - 24s - loss: 0.1343 - accuracy: 0.9498 - val_loss: 0.2530 - val_accuracy: 0.9153\n",
      "Epoch 16/20\n",
      "469/469 - 23s - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.2556 - val_accuracy: 0.9172\n",
      "Epoch 17/20\n",
      "469/469 - 21s - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.2631 - val_accuracy: 0.9132\n",
      "Epoch 18/20\n",
      "469/469 - 22s - loss: 0.1105 - accuracy: 0.9586 - val_loss: 0.2657 - val_accuracy: 0.9171\n",
      "Epoch 19/20\n",
      "469/469 - 22s - loss: 0.1038 - accuracy: 0.9610 - val_loss: 0.2698 - val_accuracy: 0.9181\n",
      "Epoch 20/20\n",
      "469/469 - 21s - loss: 0.0997 - accuracy: 0.9627 - val_loss: 0.2727 - val_accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(trainX, trainY,\n",
    " batch_size=128, epochs=20,\n",
    " verbose=2,\n",
    " validation_data=(testX, testY))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: T-shirt/top\n",
    "1: Trouser\n",
    "2: Pullover\n",
    "3: Dress\n",
    "4: Coat\n",
    "5: Sandal\n",
    "6: Shirt\n",
    "7: Sneaker\n",
    "8: Bag\n",
    "9: Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "test_img = image.load_img('bag.png', target_size=(28, 28))\n",
    "test_img = image.img_to_array(test_img)\n",
    "test_img = test_img[:,:,1].reshape(1,28,28,1)\n",
    "test_img = test_img/255\n",
    "# classifier.predict_classes(test_img)\n",
    "# (classifier.predict(test_img) > 0.5).astype(\"int32\")\n",
    "np.argmax(classifier.predict(test_img), axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f1ed5a6caa63b933f18b2de58eb1658054e234b84bf4970be74ffb1abce9f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
